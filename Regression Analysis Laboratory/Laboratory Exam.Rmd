---
title: "Laboratory Exam"
subtitle: "Simple Linear Regression"
author: "Charlene Garridos"
date: '2023-06-29'
output: 
  pdf_document:
    toc: true
    number_sections: true
---

# The Fractional Distillation Data

The purity of oxygen produced by a fractional distillation process is thought to be related to the percentage of hydrocarbons in the main condensor of the processing unit.

```{r data}
# Specify the file path relative to the working directory
file_path <- "/Users/User/Downloads/fractional_distillation_data.csv"

# Read the CSV file
fractional_distillation_data <- read.csv(file_path)

# View the data
print(fractional_distillation_data)
```
## Scatter Diagram 
a. Create a scatter diagram for the data.
```{r}
# scatter plot of propellant_age and shear_strength
plot(x = fractional_distillation_data$Hydrocarbon, y = fractional_distillation_data$Purily,
     xlab = "Hydrocarbon(%)", ylab = "Purily(%)",
     main = "Scatterplot of Hydrocarbon and Purity of Oxygen")
```

 **Least-Squares Estimation of the Parameters**

Use the lm() function to calculate the linear model based on the data set.

```{r}
# calculate model
model <- lm(data = fractional_distillation_data,
formula = Purily ~ Hydrocarbon)
```

The model object is a list of a number of different pieces of information, which can be seen by looking at the names of the objects in the list.

```{r}
# view the names of the objects in the model
names(model)
```
```{r}
model$coefficients
```

## The Least-Squares Fit 

The summary() function is a useful way to gather critical information in your model.
b. The Least-sqaures fit is
```{r}
model_summary <- summary(model)
model_summary$sigma
```

```{r}
model_summary$coefficients
```

## The Estimate

c.The estimate of $\sigma^2$ is

```{r}
sigma_squared<- (model_summary$sigma)^2
sigma_squared
```

**Hypothesis Testing on the Slope and Intercept**

```{r}
model_summary
```

```{r}
model_summary$coefficients["Hydrocarbon",]
```
```{r}
mosaic::xqt(0.95, 18)
```

## Test for Significance of Regression in the Fractional Distillation Regression Model.
d. Test for Significance of Regression in the Fractional Distillation Regression Model.

Based on the statistical analysis conducted, the t-statistic for the coefficient of Hydrocarbon, with the 95% confidence interval, is 3.386 (p < 0.003), indicating a significant relationship between hydrocarbon and the purity of oxygen. This positive t-value suggests that as the hydrocarbon increases, the purity of oxygen tends to increase. Therefore, we can infer that hydrocarbon has a substantial impact on the purity of oxygen in the fractional distillation data.

Thus, the statistically significant t-value provides strong evidence to reject $H_0 : \beta_1 = 0$ and support the conclusion that hydrocarbon is an influential factor in determining the purity of an oxygen.


```{r}
model_summary$fstatistic
```

```{r}
mosaic::xqf(0.95,1,18)
```

## An analysis-of-variance approach to test significance of regression.
e. An analysis-of-variance approach to test significance of regression.
At 95% confidence interval, the F-statistic of 11.4658 $(p < 0.003)$ obtained from the regression analysis indicates that the overall model, including the intercept and the predictor variable hydrocarbon, is statistically significant. It  suggests the inclusion of hydrocarbon as a predictor in the model significantly improves the ability to predict the purity of the oxygen compared to a model without this variable. Along with the low p-value, it indicates that there is a low probability of obtaining such a strong relationship between the predictors and the response variable by chance alone. This strengthens our confidence in the conclusion that hydrocarbon has a substantial impact on the purity of the oxygen. Therefore, the F-statistic provides strong evidence to reject $H_0 : \beta_1 = 0$.  

## 95% CI on the slope
```{r}
confint(model_summary)
```

## 95% CI on the mean purily when the hydrocarbon percentage is 1.00
```{r}
confint(model_summary$coefficients)
```

# The Steam Consumption Data

The number of pounds of steam used per month at a plant is thought to be related to the
average monthly ambient temperature.

```{r data1}
# Specify the file path relative to the working directory
file_path <- "/Users/User/Downloads/steam_consumption_data.csv"

# Read the CSV file
steam_consumption_data <- read.csv(file_path)

# View the data
print(steam_consumption_data)
```
## Scatter Diagram 
a. Create a scatter diagram for the data.
```{r}
# scatter plot of propellant_age and shear_strength
plot(x = steam_consumption_data$Temperature, y = steam_consumption_data$Usage,
     xlab = "Temperature", ylab = "Usage/1000",
     main = "Scatterplot of Temperature and Past Year's Usage")
```

 **Least-Squares Estimation of the Parameters**

Use the lm() function to calculate the linear model based on the data set.

```{r}
# calculate model
model_1 <- lm(data = steam_consumption_data,
formula = Usage ~ Temperature)
```

The model object is a list of a number of different pieces of information, which can be seen by looking at the names of the objects in the list.

```{r}
# view the names of the objects in the model
names(model_1)
```
```{r}
model_1$coefficients
```

## The Least-Squares Fit 

The summary() function is a useful way to gather critical information in your model.
b. The Least-sqaures fit is
```{r}
model_1_summary <- summary(model_1)
model_1_summary$sigma
```

```{r}
model_1_summary$coefficients
```

## The Estimate

c.The estimate of $\sigma^2$ is

```{r}
sigma_squared<- (model_1_summary$sigma)^2
sigma_squared
```


**Hypothesis Testing on the Slope and Intercept**

```{r}
model_1_summary
```

```{r}
model_1_summary$coefficients["Temperature",]
```
```{r}
mosaic::xqt(0.99, 10)
```

## Test for Significance of Regression in the Steam Consumption Regression Model.
d. Test for Significance of Regression in the Steam Consumption Regression Model.

Based on the statistical analysis conducted, the t-statistic for the coefficient of Temperature, with the 99% confidence interval, is 2.722 (p < 0.002), indicating a significant relationship between temperature and usage. This positive t-value suggests that as the temperature increases, the usage tends to increase. Therefore, we can infer that temperature has a substantial impact on the usage of the steam consumption.

Thus, the statistically significant t-value provides strong evidence to reject $H_0 : \beta_1 = 0$ and support the conclusion that temperature is an influential factor in determining the usage.

```{r}
model_1_summary$fstatistic
```

```{r}
mosaic::xqf(0.99,1,10)
```

## An analysis-of-variance approach to test significance of regression.
e. An analysis-of-variance approach to test significance of regression.
At 99% confidence interval, the F-statistic of  74122.78 $(p < 0.002)$ obtained from the regression analysis indicates that the overall model, including the intercept and the predictor variable temperature, is statistically significant. It  suggests the inclusion of temperature as a predictor in the model significantly improves the ability to predict the usage compared to a model without this variable. Along with the low p-value, it indicates that there is a low probability of obtaining such a strong relationship between the predictors and the response variable by chance alone. This strengthens our confidence in the conclusion that temperature has a substantial impact on the usage of the steam consumption. Therefore, the F-statistic provides strong evidence to reject $H_0 : \beta_1 = 0$.  

## 99% CI on the slope
```{r}
confint(model_1_summary)
```

## 99% prediction interval on the steam usage in a month with average ambient tempreature of 58 degrees.
```{r}
(new_data <- data.frame(
  Temperature = c(58, 65, 65), 
  Usage = c(455, 632, 423.09)
))
```

```{r}
predict(model_1, new_data)
```

```{r}
predict(model_1, new_data, interval = "prediction")
```
```{r}
predict(model_1, new_data, interval = "confidence")
```
```{r}
confint(model_1)
```


